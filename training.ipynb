{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlAnyZBHZ9Kd"
      },
      "source": [
        "## Cloning the google-research/FLAN repository. & Installing dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pk7pnEMGIm2E",
        "outputId": "f8bb4cc3-0b64-4af5-b7aa-d5b4046f677b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'FLAN'...\n",
            "remote: Enumerating objects: 415, done.\u001b[K\n",
            "remote: Counting objects: 100% (322/322), done.\u001b[K\n",
            "remote: Compressing objects: 100% (141/141), done.\u001b[K\n",
            "remote: Total 415 (delta 254), reused 195 (delta 181), pack-reused 93\u001b[K\n",
            "Receiving objects: 100% (415/415), 149.95 MiB | 46.36 MiB/s, done.\n",
            "Resolving deltas: 100% (259/259), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/google-research/FLAN.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cq4uWyhEbq1g",
        "outputId": "f07cacdd-d5d8-40b4-f892-4bff1074cd85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/FLAN/flan/v2\n"
          ]
        }
      ],
      "source": [
        "%cd FLAN/flan/v2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FS0NWR0Qb7Jv",
        "outputId": "35c18c48-38a8-449c-da9c-f0e02d621599"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tfds_nightly (from -r /content/FLAN/flan/v2/requirements.txt (line 1))\n",
            "  Downloading tfds_nightly-4.9.6.dev202407060044-py3-none-any.whl (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: frozendict in /usr/local/lib/python3.10/dist-packages (from -r /content/FLAN/flan/v2/requirements.txt (line 2)) (2.4.4)\n",
            "Collecting datasets (from -r /content/FLAN/flan/v2/requirements.txt (line 3))\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seqio (from -r /content/FLAN/flan/v2/requirements.txt (line 4))\n",
            "  Downloading seqio-0.0.19-py3-none-any.whl (354 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.3/354.3 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting t5 (from -r /content/FLAN/flan/v2/requirements.txt (line 5))\n",
            "  Downloading t5-0.9.4-py2.py3-none-any.whl (164 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.5/164.5 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tfds_nightly->-r /content/FLAN/flan/v2/requirements.txt (line 1)) (1.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tfds_nightly->-r /content/FLAN/flan/v2/requirements.txt (line 1)) (8.1.7)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tfds_nightly->-r /content/FLAN/flan/v2/requirements.txt (line 1)) (0.1.8)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.10/dist-packages (from tfds_nightly->-r /content/FLAN/flan/v2/requirements.txt (line 1)) (4.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tfds_nightly->-r /content/FLAN/flan/v2/requirements.txt (line 1)) (1.25.2)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tfds_nightly->-r /content/FLAN/flan/v2/requirements.txt (line 1)) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tfds_nightly->-r /content/FLAN/flan/v2/requirements.txt (line 1)) (3.20.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tfds_nightly->-r /content/FLAN/flan/v2/requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from tfds_nightly->-r /content/FLAN/flan/v2/requirements.txt (line 1)) (14.0.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from tfds_nightly->-r /content/FLAN/flan/v2/requirements.txt (line 1)) (2.31.0)\n",
            "Requirement already satisfied: simple-parsing in /usr/local/lib/python3.10/dist-packages (from tfds_nightly->-r /content/FLAN/flan/v2/requirements.txt (line 1)) (0.1.5)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tfds_nightly->-r /content/FLAN/flan/v2/requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from tfds_nightly->-r /content/FLAN/flan/v2/requirements.txt (line 1)) (2.4.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tfds_nightly->-r /content/FLAN/flan/v2/requirements.txt (line 1)) (0.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tfds_nightly->-r /content/FLAN/flan/v2/requirements.txt (line 1)) (4.66.4)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from tfds_nightly->-r /content/FLAN/flan/v2/requirements.txt (line 1)) (1.14.1)\n",
            "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tfds_nightly->-r /content/FLAN/flan/v2/requirements.txt (line 1)) (0.5.1)\n",
            "Requirement already satisfied: etils[edc,enp,epath,epy,etree]>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tfds_nightly->-r /content/FLAN/flan/v2/requirements.txt (line 1)) (1.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->-r /content/FLAN/flan/v2/requirements.txt (line 3)) (3.15.4)\n",
            "Collecting pyarrow (from tfds_nightly->-r /content/FLAN/flan/v2/requirements.txt (line 1))\n",
            "  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->-r /content/FLAN/flan/v2/requirements.txt (line 3)) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->-r /content/FLAN/flan/v2/requirements.txt (line 3))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->-r /content/FLAN/flan/v2/requirements.txt (line 3)) (2.0.3)\n",
            "Collecting requests>=2.19.0 (from tfds_nightly->-r /content/FLAN/flan/v2/requirements.txt (line 1))\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets->-r /content/FLAN/flan/v2/requirements.txt (line 3))\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets->-r /content/FLAN/flan/v2/requirements.txt (line 3))\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r /content/FLAN/flan/v2/requirements.txt (line 3)) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->-r /content/FLAN/flan/v2/requirements.txt (line 3)) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets->-r /content/FLAN/flan/v2/requirements.txt (line 3)) (0.23.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->-r /content/FLAN/flan/v2/requirements.txt (line 3)) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->-r /content/FLAN/flan/v2/requirements.txt (line 3)) (6.0.1)\n",
            "Collecting clu (from seqio->-r /content/FLAN/flan/v2/requirements.txt (line 4))\n",
            "  Downloading clu-0.0.12-py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: editdistance in /usr/local/lib/python3.10/dist-packages (from seqio->-r /content/FLAN/flan/v2/requirements.txt (line 4)) (0.6.2)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from seqio->-r /content/FLAN/flan/v2/requirements.txt (line 4)) (0.4.26)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from seqio->-r /content/FLAN/flan/v2/requirements.txt (line 4)) (0.4.26+cuda12.cudnn89)\n",
            "Collecting pyglove (from seqio->-r /content/FLAN/flan/v2/requirements.txt (line 4))\n",
            "  Downloading pyglove-0.4.4-py3-none-any.whl (577 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m577.8/577.8 kB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from seqio->-r /content/FLAN/flan/v2/requirements.txt (line 4)) (0.1.99)\n",
            "Collecting tensorflow-text (from seqio->-r /content/FLAN/flan/v2/requirements.txt (line 4))\n",
            "  Downloading tensorflow_text-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m100.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tfds_nightly (from -r /content/FLAN/flan/v2/requirements.txt (line 1))\n",
            "  Downloading tfds_nightly-4.9.2.dev202308090034-py3-none-any.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m99.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: babel in /usr/local/lib/python3.10/dist-packages (from t5->-r /content/FLAN/flan/v2/requirements.txt (line 5)) (2.15.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from t5->-r /content/FLAN/flan/v2/requirements.txt (line 5)) (0.5.0)\n",
            "Collecting mesh-tensorflow[transformer]>=0.1.13 (from t5->-r /content/FLAN/flan/v2/requirements.txt (line 5))\n",
            "  Downloading mesh_tensorflow-0.1.21-py3-none-any.whl (385 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.2/385.2 kB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from t5->-r /content/FLAN/flan/v2/requirements.txt (line 5)) (3.8.1)\n",
            "Collecting rouge-score>=0.1.2 (from t5->-r /content/FLAN/flan/v2/requirements.txt (line 5))\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sacrebleu (from t5->-r /content/FLAN/flan/v2/requirements.txt (line 5))\n",
            "  Downloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from t5->-r /content/FLAN/flan/v2/requirements.txt (line 5)) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from t5->-r /content/FLAN/flan/v2/requirements.txt (line 5)) (1.11.4)\n",
            "Collecting seqio-nightly (from t5->-r /content/FLAN/flan/v2/requirements.txt (line 5))\n",
            "  Downloading seqio_nightly-0.0.18.dev20240706-py3-none-any.whl (356 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m356.5/356.5 kB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.14 in /usr/local/lib/python3.10/dist-packages (from t5->-r /content/FLAN/flan/v2/requirements.txt (line 5)) (1.16.0)\n",
            "Requirement already satisfied: transformers>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from t5->-r /content/FLAN/flan/v2/requirements.txt (line 5)) (4.41.2)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0->tfds_nightly->-r /content/FLAN/flan/v2/requirements.txt (line 1)) (6.4.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0->tfds_nightly->-r /content/FLAN/flan/v2/requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0->tfds_nightly->-r /content/FLAN/flan/v2/requirements.txt (line 1)) (3.19.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/FLAN/flan/v2/requirements.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/FLAN/flan/v2/requirements.txt (line 3)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/FLAN/flan/v2/requirements.txt (line 3)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/FLAN/flan/v2/requirements.txt (line 3)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/FLAN/flan/v2/requirements.txt (line 3)) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/FLAN/flan/v2/requirements.txt (line 3)) (4.0.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from mesh-tensorflow[transformer]>=0.1.13->t5->-r /content/FLAN/flan/v2/requirements.txt (line 5)) (0.18.3)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from mesh-tensorflow[transformer]>=0.1.13->t5->-r /content/FLAN/flan/v2/requirements.txt (line 5)) (4.9.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tfds_nightly->-r /content/FLAN/flan/v2/requirements.txt (line 1)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tfds_nightly->-r /content/FLAN/flan/v2/requirements.txt (line 1)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tfds_nightly->-r /content/FLAN/flan/v2/requirements.txt (line 1)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tfds_nightly->-r /content/FLAN/flan/v2/requirements.txt (line 1)) (2024.6.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.7.0->t5->-r /content/FLAN/flan/v2/requirements.txt (line 5)) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.7.0->t5->-r /content/FLAN/flan/v2/requirements.txt (line 5)) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.7.0->t5->-r /content/FLAN/flan/v2/requirements.txt (line 5)) (0.4.3)\n",
            "Requirement already satisfied: flax in /usr/local/lib/python3.10/dist-packages (from clu->seqio->-r /content/FLAN/flan/v2/requirements.txt (line 4)) (0.8.4)\n",
            "Collecting ml-collections (from clu->seqio->-r /content/FLAN/flan/v2/requirements.txt (line 4))\n",
            "  Downloading ml_collections-0.1.1.tar.gz (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->seqio->-r /content/FLAN/flan/v2/requirements.txt (line 4)) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->seqio->-r /content/FLAN/flan/v2/requirements.txt (line 4)) (3.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->t5->-r /content/FLAN/flan/v2/requirements.txt (line 5)) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r /content/FLAN/flan/v2/requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r /content/FLAN/flan/v2/requirements.txt (line 3)) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r /content/FLAN/flan/v2/requirements.txt (line 3)) (2024.1)\n",
            "Requirement already satisfied: docstring-parser>=0.12 in /usr/local/lib/python3.10/dist-packages (from pyglove->seqio->-r /content/FLAN/flan/v2/requirements.txt (line 4)) (0.16)\n",
            "Collecting portalocker (from sacrebleu->t5->-r /content/FLAN/flan/v2/requirements.txt (line 5))\n",
            "  Downloading portalocker-2.10.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->t5->-r /content/FLAN/flan/v2/requirements.txt (line 5)) (0.9.0)\n",
            "Collecting colorama (from sacrebleu->t5->-r /content/FLAN/flan/v2/requirements.txt (line 5))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->t5->-r /content/FLAN/flan/v2/requirements.txt (line 5)) (4.9.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->t5->-r /content/FLAN/flan/v2/requirements.txt (line 5)) (3.5.0)\n",
            "Collecting sentencepiece (from seqio->-r /content/FLAN/flan/v2/requirements.txt (line 4))\n",
            "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow<2.17,>=2.16.1 (from tensorflow-text->seqio->-r /content/FLAN/flan/v2/requirements.txt (line 4))\n",
            "  Downloading tensorflow-2.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (590.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->seqio->-r /content/FLAN/flan/v2/requirements.txt (line 4)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->seqio->-r /content/FLAN/flan/v2/requirements.txt (line 4)) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->seqio->-r /content/FLAN/flan/v2/requirements.txt (line 4)) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->seqio->-r /content/FLAN/flan/v2/requirements.txt (line 4)) (0.2.0)\n",
            "Collecting h5py>=3.10.0 (from tensorflow<2.17,>=2.16.1->tensorflow-text->seqio->-r /content/FLAN/flan/v2/requirements.txt (line 4))\n",
            "  Downloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m110.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->seqio->-r /content/FLAN/flan/v2/requirements.txt (line 4)) (18.1.1)\n",
            "Collecting ml-dtypes>=0.2.0 (from jax->seqio->-r /content/FLAN/flan/v2/requirements.txt (line 4))\n",
            "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->seqio->-r /content/FLAN/flan/v2/requirements.txt (line 4)) (67.7.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->seqio->-r /content/FLAN/flan/v2/requirements.txt (line 4)) (1.64.1)\n",
            "Collecting tensorboard<2.17,>=2.16 (from tensorflow<2.17,>=2.16.1->tensorflow-text->seqio->-r /content/FLAN/flan/v2/requirements.txt (line 4))\n",
            "  Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m108.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras>=3.0.0 (from tensorflow<2.17,>=2.16.1->tensorflow-text->seqio->-r /content/FLAN/flan/v2/requirements.txt (line 4))\n",
            "  Downloading keras-3.4.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->seqio->-r /content/FLAN/flan/v2/requirements.txt (line 4)) (0.37.0)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax->clu->seqio->-r /content/FLAN/flan/v2/requirements.txt (line 4)) (1.0.8)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (from flax->clu->seqio->-r /content/FLAN/flan/v2/requirements.txt (line 4)) (0.2.2)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/dist-packages (from flax->clu->seqio->-r /content/FLAN/flan/v2/requirements.txt (line 4)) (0.4.4)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax->clu->seqio->-r /content/FLAN/flan/v2/requirements.txt (line 4)) (0.1.45)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.10/dist-packages (from flax->clu->seqio->-r /content/FLAN/flan/v2/requirements.txt (line 4)) (13.7.1)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.10/dist-packages (from ml-collections->clu->seqio->-r /content/FLAN/flan/v2/requirements.txt (line 4)) (21.6.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.17,>=2.16.1->tensorflow-text->seqio->-r /content/FLAN/flan/v2/requirements.txt (line 4)) (0.43.0)\n",
            "Collecting namex (from keras>=3.0.0->tensorflow<2.17,>=2.16.1->tensorflow-text->seqio->-r /content/FLAN/flan/v2/requirements.txt (line 4))\n",
            "  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
            "Collecting optree (from keras>=3.0.0->tensorflow<2.17,>=2.16.1->tensorflow-text->seqio->-r /content/FLAN/flan/v2/requirements.txt (line 4))\n",
            "  Downloading optree-0.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (347 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.7/347.7 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax->clu->seqio->-r /content/FLAN/flan/v2/requirements.txt (line 4)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax->clu->seqio->-r /content/FLAN/flan/v2/requirements.txt (line 4)) (2.16.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text->seqio->-r /content/FLAN/flan/v2/requirements.txt (line 4)) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text->seqio->-r /content/FLAN/flan/v2/requirements.txt (line 4)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text->seqio->-r /content/FLAN/flan/v2/requirements.txt (line 4)) (3.0.3)\n",
            "Requirement already satisfied: chex>=0.1.86 in /usr/local/lib/python3.10/dist-packages (from optax->flax->clu->seqio->-r /content/FLAN/flan/v2/requirements.txt (line 4)) (0.1.86)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->clu->seqio->-r /content/FLAN/flan/v2/requirements.txt (line 4)) (1.6.0)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.86->optax->flax->clu->seqio->-r /content/FLAN/flan/v2/requirements.txt (line 4)) (0.12.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax->clu->seqio->-r /content/FLAN/flan/v2/requirements.txt (line 4)) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text->seqio->-r /content/FLAN/flan/v2/requirements.txt (line 4)) (2.1.5)\n",
            "Building wheels for collected packages: rouge-score, ml-collections\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=2973a52de930b8236298ab35ebe2bd3e6996e845c2704455f109325bdafa568b\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "  Building wheel for ml-collections (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ml-collections: filename=ml_collections-0.1.1-py3-none-any.whl size=94506 sha256=36ac31c52a89f54e9483ae25f527b66ef7b90cc9b6ce9ae63ab76a90a5c12937\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/89/c9/a9b87790789e94aadcfc393c283e3ecd5ab916aed0a31be8fe\n",
            "Successfully built rouge-score ml-collections\n",
            "Installing collected packages: sentencepiece, namex, xxhash, requests, pyglove, pyarrow, portalocker, optree, ml-dtypes, ml-collections, mesh-tensorflow, h5py, dill, colorama, tensorboard, sacrebleu, rouge-score, multiprocess, keras, tensorflow, datasets, tfds_nightly, tensorflow-text, clu, seqio-nightly, seqio, t5\n",
            "  Attempting uninstall: sentencepiece\n",
            "    Found existing installation: sentencepiece 0.1.99\n",
            "    Uninstalling sentencepiece-0.1.99:\n",
            "      Successfully uninstalled sentencepiece-0.1.99\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.2.0\n",
            "    Uninstalling ml-dtypes-0.2.0:\n",
            "      Successfully uninstalled ml-dtypes-0.2.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.9.0\n",
            "    Uninstalling h5py-3.9.0:\n",
            "      Successfully uninstalled h5py-3.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.16.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed clu-0.0.12 colorama-0.4.6 datasets-2.20.0 dill-0.3.8 h5py-3.11.0 keras-3.4.1 mesh-tensorflow-0.1.21 ml-collections-0.1.1 ml-dtypes-0.3.2 multiprocess-0.70.16 namex-0.0.8 optree-0.12.1 portalocker-2.10.0 pyarrow-16.1.0 pyglove-0.4.4 requests-2.32.3 rouge-score-0.1.2 sacrebleu-2.4.2 sentencepiece-0.2.0 seqio-0.0.19 seqio-nightly-0.0.18.dev20240706 t5-0.9.4 tensorboard-2.16.2 tensorflow-2.16.2 tensorflow-text-2.16.1 tfds_nightly-4.9.2.dev202308090034 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -r /content/FLAN/flan/v2/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVqwZ2_db-nm",
        "outputId": "ad54c755-7eee-46d0-9fbd-d1fcf59bc413"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting absl-py==0.12.0 (from -r /content/FLAN/requirements.txt (line 1))\n",
            "  Downloading absl_py-0.12.0-py3-none-any.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.10/dist-packages (from -r /content/FLAN/requirements.txt (line 2)) (1.6.3)\n",
            "Collecting attrs==21.2.0 (from -r /content/FLAN/requirements.txt (line 3))\n",
            "  Downloading attrs-21.2.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.7/53.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Babel==2.9.1 (from -r /content/FLAN/requirements.txt (line 4))\n",
            "  Downloading Babel-2.9.1-py2.py3-none-any.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cachetools==4.2.2 (from -r /content/FLAN/requirements.txt (line 5))\n",
            "  Downloading cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
            "Collecting certifi==2021.5.30 (from -r /content/FLAN/requirements.txt (line 6))\n",
            "  Downloading certifi-2021.5.30-py2.py3-none-any.whl (145 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.5/145.5 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting charset-normalizer==2.0.4 (from -r /content/FLAN/requirements.txt (line 7))\n",
            "  Downloading charset_normalizer-2.0.4-py3-none-any.whl (36 kB)\n",
            "Collecting clang==5.0 (from -r /content/FLAN/requirements.txt (line 8))\n",
            "  Downloading clang-5.0.tar.gz (30 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting click==8.0.1 (from -r /content/FLAN/requirements.txt (line 9))\n",
            "  Downloading click-8.0.1-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.4/97.4 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorama==0.4.4 (from -r /content/FLAN/requirements.txt (line 10))\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting dill==0.3.4 (from -r /content/FLAN/requirements.txt (line 11))\n",
            "  Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.9/86.9 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting editdistance==0.5.3 (from -r /content/FLAN/requirements.txt (line 12))\n",
            "  Downloading editdistance-0.5.3.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting filelock==3.0.12 (from -r /content/FLAN/requirements.txt (line 13))\n",
            "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
            "Collecting flatbuffers==1.12 (from -r /content/FLAN/requirements.txt (line 14))\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Collecting future==0.18.2 (from -r /content/FLAN/requirements.txt (line 15))\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.2/829.2 kB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gast==0.4.0 (from -r /content/FLAN/requirements.txt (line 16))\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Collecting gin-config==0.4.0 (from -r /content/FLAN/requirements.txt (line 17))\n",
            "  Downloading gin_config-0.4.0-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-auth==1.35.0 (from -r /content/FLAN/requirements.txt (line 18))\n",
            "  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.9/152.9 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-auth-oauthlib==0.4.5 (from -r /content/FLAN/requirements.txt (line 19))\n",
            "  Downloading google_auth_oauthlib-0.4.5-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: google-pasta==0.2.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/FLAN/requirements.txt (line 20)) (0.2.0)\n",
            "Collecting googleapis-common-protos==1.53.0 (from -r /content/FLAN/requirements.txt (line 21))\n",
            "  Downloading googleapis_common_protos-1.53.0-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.2/198.2 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting grpcio==1.39.0 (from -r /content/FLAN/requirements.txt (line 22))\n",
            "  Downloading grpcio-1.39.0.tar.gz (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting h5py==3.1.0 (from -r /content/FLAN/requirements.txt (line 23))\n",
            "  Downloading h5py-3.1.0.tar.gz (371 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m371.4/371.4 kB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpip subprocess to install backend dependencies\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m \u001b[32mpip subprocess to install backend dependencies\u001b[0m did not run successfully.\n",
            "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"
          ]
        }
      ],
      "source": [
        "!pip install -r /content/FLAN/requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_7m3CMOdcox"
      },
      "source": [
        "## Collecting datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIIXw8lBcnq6",
        "outputId": "e382946f-cae9-4c7f-99b7-6312a48978fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/FLAN\n"
          ]
        }
      ],
      "source": [
        "%cd /content/FLAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NDnGtuNeMoA",
        "outputId": "7d68998a-c6d8-499e-c3de-600ffc566f63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  flan/v2/niv2_few_shot_data/niv2_exemplars.jsonl-00000-of-00010.zip\n",
            "  inflating: flan/v2/niv2_few_shot_data/niv2_exemplars.jsonl-00000-of-00010  \n",
            "Archive:  flan/v2/niv2_few_shot_data/niv2_exemplars.jsonl-00001-of-00010.zip\n",
            "  inflating: flan/v2/niv2_few_shot_data/niv2_exemplars.jsonl-00001-of-00010  \n",
            "Archive:  flan/v2/niv2_few_shot_data/niv2_exemplars.jsonl-00002-of-00010.zip\n",
            "  inflating: flan/v2/niv2_few_shot_data/niv2_exemplars.jsonl-00002-of-00010  \n",
            "Archive:  flan/v2/niv2_few_shot_data/niv2_exemplars.jsonl-00003-of-00010.zip\n",
            "  inflating: flan/v2/niv2_few_shot_data/niv2_exemplars.jsonl-00003-of-00010  \n",
            "Archive:  flan/v2/niv2_few_shot_data/niv2_exemplars.jsonl-00004-of-00010.zip\n",
            "  inflating: flan/v2/niv2_few_shot_data/niv2_exemplars.jsonl-00004-of-00010  \n",
            "Archive:  flan/v2/niv2_few_shot_data/niv2_exemplars.jsonl-00005-of-00010.zip\n",
            "  inflating: flan/v2/niv2_few_shot_data/niv2_exemplars.jsonl-00005-of-00010  \n",
            "Archive:  flan/v2/niv2_few_shot_data/niv2_exemplars.jsonl-00006-of-00010.zip\n",
            "  inflating: flan/v2/niv2_few_shot_data/niv2_exemplars.jsonl-00006-of-00010  \n",
            "Archive:  flan/v2/niv2_few_shot_data/niv2_exemplars.jsonl-00007-of-00010.zip\n",
            "  inflating: flan/v2/niv2_few_shot_data/niv2_exemplars.jsonl-00007-of-00010  \n",
            "Archive:  flan/v2/niv2_few_shot_data/niv2_exemplars.jsonl-00008-of-00010.zip\n",
            "  inflating: flan/v2/niv2_few_shot_data/niv2_exemplars.jsonl-00008-of-00010  \n",
            "Archive:  flan/v2/niv2_few_shot_data/niv2_exemplars.jsonl-00009-of-00010.zip\n",
            "  inflating: flan/v2/niv2_few_shot_data/niv2_exemplars.jsonl-00009-of-00010  \n"
          ]
        }
      ],
      "source": [
        "!unzip flan/v2/niv2_few_shot_data/niv2_exemplars.jsonl-00000-of-00010.zip -d flan/v2/niv2_few_shot_data/\n",
        "!unzip flan/v2/niv2_few_shot_data/niv2_exemplars.jsonl-00001-of-00010.zip -d flan/v2/niv2_few_shot_data/\n",
        "!unzip flan/v2/niv2_few_shot_data/niv2_exemplars.jsonl-00002-of-00010.zip -d flan/v2/niv2_few_shot_data/\n",
        "!unzip flan/v2/niv2_few_shot_data/niv2_exemplars.jsonl-00003-of-00010.zip -d flan/v2/niv2_few_shot_data/\n",
        "!unzip flan/v2/niv2_few_shot_data/niv2_exemplars.jsonl-00004-of-00010.zip -d flan/v2/niv2_few_shot_data/\n",
        "!unzip flan/v2/niv2_few_shot_data/niv2_exemplars.jsonl-00005-of-00010.zip -d flan/v2/niv2_few_shot_data/\n",
        "!unzip flan/v2/niv2_few_shot_data/niv2_exemplars.jsonl-00006-of-00010.zip -d flan/v2/niv2_few_shot_data/\n",
        "!unzip flan/v2/niv2_few_shot_data/niv2_exemplars.jsonl-00007-of-00010.zip -d flan/v2/niv2_few_shot_data/\n",
        "!unzip flan/v2/niv2_few_shot_data/niv2_exemplars.jsonl-00008-of-00010.zip -d flan/v2/niv2_few_shot_data/\n",
        "!unzip flan/v2/niv2_few_shot_data/niv2_exemplars.jsonl-00009-of-00010.zip -d flan/v2/niv2_few_shot_data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asnRw87Nfi4D",
        "outputId": "11195b52-b298-4551-ce02-e13fe5f87a93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-07-06 17:31:02.237105: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-06 17:31:02.262931: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-06 17:31:02.262984: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-07-06 17:31:03.344003: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-07-06 17:31:05.302818: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2024-07-06 17:31:11.243161: W external/local_tsl/tsl/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"NOT_FOUND: Error executing an HTTP request: HTTP response code 404\".\n",
            "\u001b[1mDownloading and preparing dataset 11.10 MiB (download: 11.10 MiB, generated: Unknown size, total: 11.10 MiB) to /root/tensorflow_datasets/aeslc/1.0.0...\u001b[0m\n",
            "Dl Completed...: 0 url [00:00, ? url/s]\n",
            "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:00<?, ? url/s]\n",
            "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:00<?, ? url/s]\n",
            "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:00, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:00<?, ? url/s]\n",
            "Dl Size...: 1 MiB [00:00,  1.11 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:00<?, ? url/s]\n",
            "Dl Size...: 2 MiB [00:00,  1.11 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:00, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...: 3 MiB [00:01,  3.57 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...: 4 MiB [00:01,  3.57 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...: 5 MiB [00:01,  3.57 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...: 6 MiB [00:01,  3.57 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:01, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...: 7 MiB [00:01,  9.03 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...: 8 MiB [00:01,  9.03 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...: 9 MiB [00:01,  9.03 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:01, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...: 10 MiB [00:01, 11.34 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...: 11 MiB [00:01, 11.34 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...: 100% 1/1 [00:01<00:00,  1.33s/ url]\n",
            "Dl Size...: 11 MiB [00:01, 11.34 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:01, ? file/s]\n",
            "Dl Size...: 11 MiB [00:01,  8.25 MiB/s]\n",
            "Dl Completed...: 100% 1/1 [00:01<00:00,  1.33s/ url]\n",
            "ERROR:absl:Failed to load task 'aeslc_template_0to10_no_opt_x_shot' as part of mixture 'flan2022_submix'\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/FLAN/flan/v2/run_example.py\", line 96, in <module>\n",
            "    dataset = selected_mixture.get_dataset(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/seqio/dataset_providers.py\", line 2041, in get_dataset\n",
            "    ds = self.get_task_dataset(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/seqio/dataset_providers.py\", line 1955, in get_task_dataset\n",
            "    return task.get_dataset(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/seqio/dataset_providers.py\", line 1622, in get_dataset\n",
            "    ds = source.get_dataset(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/seqio/experimental.py\", line 372, in get_dataset\n",
            "    train_ds = _get_maybe_sharded_dataset(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/seqio/experimental.py\", line 335, in _get_maybe_sharded_dataset\n",
            "    ds = self._original_source.get_dataset(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/seqio/dataset_providers.py\", line 556, in get_dataset\n",
            "    return self.tfds_dataset.load(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/seqio/utils.py\", line 366, in load\n",
            "    return tfds.load(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/core/logging/__init__.py\", line 166, in __call__\n",
            "    return function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/core/load.py\", line 639, in load\n",
            "    _download_and_prepare_builder(dbuilder, download, download_and_prepare_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/core/load.py\", line 498, in _download_and_prepare_builder\n",
            "    dbuilder.download_and_prepare(**download_and_prepare_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/core/logging/__init__.py\", line 166, in __call__\n",
            "    return function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/core/dataset_builder.py\", line 691, in download_and_prepare\n",
            "    self._download_and_prepare(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/core/dataset_builder.py\", line 1546, in _download_and_prepare\n",
            "    split_generators = self._split_generators(  # pylint: disable=unexpected-keyword-arg\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/datasets/aeslc/aeslc_dataset_builder.py\", line 46, in _split_generators\n",
            "    dl_path = dl_manager.download_and_extract(_URL)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/core/download/download_manager.py\", line 688, in download_and_extract\n",
            "    return _map_promise(self._download_extract, url_or_urls)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/core/download/download_manager.py\", line 831, in _map_promise\n",
            "    res = tree_utils.map_structure(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tree/__init__.py\", line 435, in map_structure\n",
            "    [func(*args) for args in zip(*map(flatten, structures))])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tree/__init__.py\", line 435, in <listcomp>\n",
            "    [func(*args) for args in zip(*map(flatten, structures))])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/core/download/download_manager.py\", line 832, in <lambda>\n",
            "    lambda p: p.get(), all_promises\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/promise/promise.py\", line 512, in get\n",
            "    return self._target_settled_value(_raise=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/promise/promise.py\", line 516, in _target_settled_value\n",
            "    return self._target()._settled_value(_raise)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/promise/promise.py\", line 226, in _settled_value\n",
            "    reraise(type(raise_val), raise_val, self._traceback)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/six.py\", line 719, in reraise\n",
            "    raise value\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/promise/promise.py\", line 87, in try_catch\n",
            "    return (handler(*args, **kwargs), None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/core/download/download_manager.py\", line 408, in <lambda>\n",
            "    lambda dl_result: self._register_or_validate_checksums(  # pylint: disable=g-long-lambda\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/core/download/download_manager.py\", line 465, in _register_or_validate_checksums\n",
            "    _validate_checksums(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/core/download/download_manager.py\", line 809, in _validate_checksums\n",
            "    raise NonMatchingChecksumError(msg)\n",
            "tensorflow_datasets.core.download.download_manager.NonMatchingChecksumError: Artifact https://github.com/ryanzhumich/AESLC/archive/master.zip, downloaded to /root/tensorflow_datasets/downloads/ryanzhumich_AESLC_archive_masterACSpoxw627Ay4UrkswMeyz6RrOey8kKfkhEM4VySJWU.zip.tmp.90adabd7d9904db081d117ca4676b284/AESLC-master.zip, has wrong checksum:\n",
            "* Expected: UrlInfo(size=11.10 MiB, checksum='b5ea2ffb837c5cfb9b033d62b3940a8a2330a9eb69bd2a39a9f55db6a23a40a4', filename='AESLC-master.zip')\n",
            "* Got: UrlInfo(size=11.11 MiB, checksum='cd042fa034790609468250518d44060017df153c382ae888091a37d5fa320032', filename='AESLC-master.zip')\n",
            "To debug, see: https://www.tensorflow.org/datasets/overview#fixing_nonmatchingchecksumerror\n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=. python /content/FLAN/flan/v2/run_example.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDrT90KCG3yq"
      },
      "source": [
        "## Due to some checksum related issue I am not able to download the datasets. But we can download it seperately thorugh hugging face.\n",
        "- [DataProvenanceInitiative/t0_submix_original](https://huggingface.co/datasets/DataProvenanceInitiative/t0_submix_original) -- 2.73 GB\n",
        "- [DataProvenanceInitiative/niv2_submix_original](https://huggingface.co/datasets/DataProvenanceInitiative/niv2_submix_original) -- 7.61 GB\n",
        "- [DataProvenanceInitiative/flan2021_submix_original](https://huggingface.co/datasets/DataProvenanceInitiative/flan2021_submix_original) -- 5.49 GB\n",
        "- [DataProvenanceInitiative/cot_submix_original](https://huggingface.co/datasets/DataProvenanceInitiative/cot_submix_original) -- 100 MB\n",
        "- [DataProvenanceInitiative/dialog_submix_original](https://huggingface.co/datasets/DataProvenanceInitiative/dialog_submix_original) -- 583 MB\n",
        "- Now according to the assignment use case I will combine these datasets into one mixture and name it flan2024 dataset and then perform preprocess as mentioned."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- To Get you know more about the dataset, The `COMBINED FLAN-V2` Dataset is a combination of ChatGPT responses and GPT-4 responses to achieve more structured and remarkable performance with open source language models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocessing Steps\n",
        "- Remove instructions with less than 100 tokens in response.\n",
        "- Data deduplication by doing grouping using cosine similarity (threshold>0.95). CANNOT use TF-IDF for this purpose.\n",
        "- Plot a token distribution graph.\n",
        "- Publish this dataset on huggingface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Initialize all the parquet files and convert it to csv file to perform operation better.\n",
        "\n",
        "df_cot = pd.read_parquet(\"/Users/karthiksagar/Mistral-Finetune-flan2022/Datasets/cot_submix/train-00000-of-00001-bea22566b1d2393f.parquet\")\n",
        "df_t0 = pd.read_parquet(\"/Users/karthiksagar/Mistral-Finetune-flan2022/Datasets/t0_submix/train-00000-of-00001-0a6693a25fc4a25e.parquet\")\n",
        "df_dialogue = pd.read_parquet(\"/Users/karthiksagar/Mistral-Finetune-flan2022/Datasets/dialogue_submix/train-00000-of-00001-0aecb489ddece98b.parquet\")\n",
        "\n",
        "# flan2021 & niv2 contains to parquet files because of huge data (so we will concatinate them)\n",
        "df_flan_1 = pd.read_parquet(\"/Users/karthiksagar/Mistral-Finetune-flan2022/Datasets/flan2021_submix/train-00000-of-00002-3567632fcf5dcbb6.parquet\")\n",
        "df_flan_2 = pd.read_parquet(\"/Users/karthiksagar/Mistral-Finetune-flan2022/Datasets/flan2021_submix/train-00001-of-00002-074f71469590ee0d.parquet\")\n",
        "df_niv2_1 = pd.read_parquet(\"/Users/karthiksagar/Mistral-Finetune-flan2022/Datasets/niv2_submix/train-00000-of-00002-a559b7e8dec9a49b.parquet\")\n",
        "df_niv2_2 = pd.read_parquet(\"/Users/karthiksagar/Mistral-Finetune-flan2022/Datasets/niv2_submix/train-00001-of-00002-068633fabd53e140.parquet\")\n",
        "\n",
        "df_flan = pd.concat([df_flan_1, df_flan_2])\n",
        "df_niv2 = pd.concat([df_niv2_1, df_niv2_2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CoT Shape : (183848, 5)\n",
            "flan2021 Shape : (5362361, 5)\n",
            "niv2 Shape : (10066896, 5)\n",
            "t0 Shape : (1650308, 5)\n",
            "Dialogue Shape : (553869, 5)\n"
          ]
        }
      ],
      "source": [
        "print(f\"CoT Shape : {df_cot.shape}\")\n",
        "print(f\"flan2021 Shape : {df_flan.shape}\")\n",
        "print(f\"niv2 Shape : {df_niv2.shape}\")\n",
        "print(f\"t0 Shape : {df_t0.shape}\")\n",
        "print(f\"Dialogue Shape : {df_dialogue.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>inputs</th>\n",
              "      <th>targets</th>\n",
              "      <th>task_source</th>\n",
              "      <th>task_name</th>\n",
              "      <th>template_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A dirt biker cannot be coming around a turn an...</td>\n",
              "      <td>Premise: \"Man scaling wall with fire in hand.\"...</td>\n",
              "      <td>CoT</td>\n",
              "      <td>cot_esnli_ii</td>\n",
              "      <td>fs_opt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Teacher: Which of the following sentences is n...</td>\n",
              "      <td>Orange juice does not taste good on cereal.\\nT...</td>\n",
              "      <td>CoT</td>\n",
              "      <td>cot_sensemaking</td>\n",
              "      <td>fs_opt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Q: The Rotary Club is holding its annual fundr...</td>\n",
              "      <td>Natalia sold 48 / 2 = 24 clips in May. Natalia...</td>\n",
              "      <td>CoT</td>\n",
              "      <td>cot_gsm8k</td>\n",
              "      <td>fs_opt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Of the following two sentences, which one is a...</td>\n",
              "      <td>Orange juice does not taste good on cereal. Fi...</td>\n",
              "      <td>CoT</td>\n",
              "      <td>cot_sensemaking</td>\n",
              "      <td>zs_opt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[QUESTION] If \"A dirt biker coming around a tu...</td>\n",
              "      <td>Just because a man is scaling a wall doesn't i...</td>\n",
              "      <td>CoT</td>\n",
              "      <td>cot_esnli</td>\n",
              "      <td>fs_opt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183843</th>\n",
              "      <td>The dog curled up for a nap, it was tuckered o...</td>\n",
              "      <td>Walked is moved at regular pace by lifting and...</td>\n",
              "      <td>CoT</td>\n",
              "      <td>cot_ecqa</td>\n",
              "      <td>zs_opt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183844</th>\n",
              "      <td>Can we conclude from \"Two harley-davison polic...</td>\n",
              "      <td>yes\\nExplanation: Giving a bath to a baby mean...</td>\n",
              "      <td>CoT</td>\n",
              "      <td>cot_esnli</td>\n",
              "      <td>fs_opt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183845</th>\n",
              "      <td>For this chain-of-thought reasoning and answer...</td>\n",
              "      <td>Q: Where might there be lots of different lawn...</td>\n",
              "      <td>CoT</td>\n",
              "      <td>cot_ecqa_ii</td>\n",
              "      <td>zs_opt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183846</th>\n",
              "      <td>Can we conclude from \"A barber giving a haircu...</td>\n",
              "      <td>In order for the barber to be giving a haircut...</td>\n",
              "      <td>CoT</td>\n",
              "      <td>cot_esnli</td>\n",
              "      <td>zs_opt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183847</th>\n",
              "      <td>Q: On a school trip to the seashore, Alan and ...</td>\n",
              "      <td>The first two tanks need 8 x 2 = 16 gallons of...</td>\n",
              "      <td>CoT</td>\n",
              "      <td>cot_gsm8k</td>\n",
              "      <td>fs_opt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>183848 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   inputs  \\\n",
              "0       A dirt biker cannot be coming around a turn an...   \n",
              "1       Teacher: Which of the following sentences is n...   \n",
              "2       Q: The Rotary Club is holding its annual fundr...   \n",
              "3       Of the following two sentences, which one is a...   \n",
              "4       [QUESTION] If \"A dirt biker coming around a tu...   \n",
              "...                                                   ...   \n",
              "183843  The dog curled up for a nap, it was tuckered o...   \n",
              "183844  Can we conclude from \"Two harley-davison polic...   \n",
              "183845  For this chain-of-thought reasoning and answer...   \n",
              "183846  Can we conclude from \"A barber giving a haircu...   \n",
              "183847  Q: On a school trip to the seashore, Alan and ...   \n",
              "\n",
              "                                                  targets task_source  \\\n",
              "0       Premise: \"Man scaling wall with fire in hand.\"...         CoT   \n",
              "1       Orange juice does not taste good on cereal.\\nT...         CoT   \n",
              "2       Natalia sold 48 / 2 = 24 clips in May. Natalia...         CoT   \n",
              "3       Orange juice does not taste good on cereal. Fi...         CoT   \n",
              "4       Just because a man is scaling a wall doesn't i...         CoT   \n",
              "...                                                   ...         ...   \n",
              "183843  Walked is moved at regular pace by lifting and...         CoT   \n",
              "183844  yes\\nExplanation: Giving a bath to a baby mean...         CoT   \n",
              "183845  Q: Where might there be lots of different lawn...         CoT   \n",
              "183846  In order for the barber to be giving a haircut...         CoT   \n",
              "183847  The first two tanks need 8 x 2 = 16 gallons of...         CoT   \n",
              "\n",
              "              task_name template_type  \n",
              "0          cot_esnli_ii        fs_opt  \n",
              "1       cot_sensemaking        fs_opt  \n",
              "2             cot_gsm8k        fs_opt  \n",
              "3       cot_sensemaking        zs_opt  \n",
              "4             cot_esnli        fs_opt  \n",
              "...                 ...           ...  \n",
              "183843         cot_ecqa        zs_opt  \n",
              "183844        cot_esnli        fs_opt  \n",
              "183845      cot_ecqa_ii        zs_opt  \n",
              "183846        cot_esnli        zs_opt  \n",
              "183847        cot_gsm8k        fs_opt  \n",
              "\n",
              "[183848 rows x 5 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_cot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>inputs</th>\n",
              "      <th>targets</th>\n",
              "      <th>task_source</th>\n",
              "      <th>task_name</th>\n",
              "      <th>template_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Example conversation: DIALOG:\\nWhat is the dif...</td>\n",
              "      <td>Cheshmeh Bid, Lorestan Cheshmeh Bid (, also Ro...</td>\n",
              "      <td>Dialog</td>\n",
              "      <td>wiki_dialog</td>\n",
              "      <td>fs_opt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Example conversation: DIALOG:\\nWhat is the dif...</td>\n",
              "      <td>Cheshmeh Bid, Lorestan Cheshmeh Bid (, also Ro...</td>\n",
              "      <td>Dialog</td>\n",
              "      <td>wiki_dialog</td>\n",
              "      <td>fs_opt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2-way dialog:\\nPerson 1: What is Cheshmeh Bid,...</td>\n",
              "      <td>At the 2006 census, its population was 151, in...</td>\n",
              "      <td>Dialog</td>\n",
              "      <td>wiki_dialog</td>\n",
              "      <td>zs_opt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DIALOG:\\nWhat is known about the Revuboè coal ...</td>\n",
              "      <td>Customer cost Customer cost refers not only to...</td>\n",
              "      <td>Dialog</td>\n",
              "      <td>wiki_dialog</td>\n",
              "      <td>fs_opt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CONVERSATION:Conversation:\\n(A) What is meant ...</td>\n",
              "      <td>Purchase costs consist of the cost of searchin...</td>\n",
              "      <td>Dialog</td>\n",
              "      <td>wiki_dialog</td>\n",
              "      <td>zs_opt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>553864</th>\n",
              "      <td>Write the response.  -- What is the permanent ...</td>\n",
              "      <td>These American works are frequently requested ...</td>\n",
              "      <td>Dialog</td>\n",
              "      <td>wiki_dialog</td>\n",
              "      <td>zs_opt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>553865</th>\n",
              "      <td>Write the conversation response. CONVERSATION:...</td>\n",
              "      <td>The plan did not increase existing taxes from ...</td>\n",
              "      <td>Dialog</td>\n",
              "      <td>wiki_dialog</td>\n",
              "      <td>zs_opt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>553866</th>\n",
              "      <td>Read the dialog and predict the next turn. DIA...</td>\n",
              "      <td>It was their intention that this race meeting ...</td>\n",
              "      <td>Dialog</td>\n",
              "      <td>wiki_dialog</td>\n",
              "      <td>fs_opt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>553867</th>\n",
              "      <td>Fill in the response. Phone call:\\nP1: What wa...</td>\n",
              "      <td>On August 26, 2016, he signed with Nagoya Diam...</td>\n",
              "      <td>Dialog</td>\n",
              "      <td>wiki_dialog</td>\n",
              "      <td>zs_opt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>553868</th>\n",
              "      <td>Example conversation: Write the response (star...</td>\n",
              "      <td>Response: On July 20, 2009, shortly after The ...</td>\n",
              "      <td>Dialog</td>\n",
              "      <td>wiki_dialog</td>\n",
              "      <td>fs_opt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>553869 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   inputs  \\\n",
              "0       Example conversation: DIALOG:\\nWhat is the dif...   \n",
              "1       Example conversation: DIALOG:\\nWhat is the dif...   \n",
              "2       2-way dialog:\\nPerson 1: What is Cheshmeh Bid,...   \n",
              "3       DIALOG:\\nWhat is known about the Revuboè coal ...   \n",
              "4       CONVERSATION:Conversation:\\n(A) What is meant ...   \n",
              "...                                                   ...   \n",
              "553864  Write the response.  -- What is the permanent ...   \n",
              "553865  Write the conversation response. CONVERSATION:...   \n",
              "553866  Read the dialog and predict the next turn. DIA...   \n",
              "553867  Fill in the response. Phone call:\\nP1: What wa...   \n",
              "553868  Example conversation: Write the response (star...   \n",
              "\n",
              "                                                  targets task_source  \\\n",
              "0       Cheshmeh Bid, Lorestan Cheshmeh Bid (, also Ro...      Dialog   \n",
              "1       Cheshmeh Bid, Lorestan Cheshmeh Bid (, also Ro...      Dialog   \n",
              "2       At the 2006 census, its population was 151, in...      Dialog   \n",
              "3       Customer cost Customer cost refers not only to...      Dialog   \n",
              "4       Purchase costs consist of the cost of searchin...      Dialog   \n",
              "...                                                   ...         ...   \n",
              "553864  These American works are frequently requested ...      Dialog   \n",
              "553865  The plan did not increase existing taxes from ...      Dialog   \n",
              "553866  It was their intention that this race meeting ...      Dialog   \n",
              "553867  On August 26, 2016, he signed with Nagoya Diam...      Dialog   \n",
              "553868  Response: On July 20, 2009, shortly after The ...      Dialog   \n",
              "\n",
              "          task_name template_type  \n",
              "0       wiki_dialog        fs_opt  \n",
              "1       wiki_dialog        fs_opt  \n",
              "2       wiki_dialog        zs_opt  \n",
              "3       wiki_dialog        fs_opt  \n",
              "4       wiki_dialog        zs_opt  \n",
              "...             ...           ...  \n",
              "553864  wiki_dialog        zs_opt  \n",
              "553865  wiki_dialog        zs_opt  \n",
              "553866  wiki_dialog        fs_opt  \n",
              "553867  wiki_dialog        zs_opt  \n",
              "553868  wiki_dialog        fs_opt  \n",
              "\n",
              "[553869 rows x 5 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_dialogue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>inputs</th>\n",
              "      <th>targets</th>\n",
              "      <th>task_source</th>\n",
              "      <th>task_name</th>\n",
              "      <th>template_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Aleksandr Chumakov, club, FC Torpedo Moscow; F...</td>\n",
              "      <td>Aleksandr Chumakov has played for FC Torpedo M...</td>\n",
              "      <td>Flan2021</td>\n",
              "      <td>gem/web_nlg_en:1.1.0</td>\n",
              "      <td>zs_noopt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I kill Kurtz, they kill me, the brass running ...</td>\n",
              "      <td>Já zabiju Kurtze, oni zabijou mě, hlavouni, kt...</td>\n",
              "      <td>Flan2021</td>\n",
              "      <td>wmt16_translate/cs-en:1.0.0</td>\n",
              "      <td>zs_noopt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i'm 10x cooler than all of you! \\nWhat is the ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>Flan2021</td>\n",
              "      <td>sentiment140:1.0.0</td>\n",
              "      <td>zs_noopt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test: Tämä tarkoittaa, että avustuksia on jaet...</td>\n",
              "      <td>Returning to the Palestinian elections, I do n...</td>\n",
              "      <td>Flan2021</td>\n",
              "      <td>wmt16_translate/fi-en:1.0.0</td>\n",
              "      <td>fs_noopt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How do you say \"In this regard, we would like ...</td>\n",
              "      <td>En este sentido, quisiéramos brindar un agrade...</td>\n",
              "      <td>Flan2021</td>\n",
              "      <td>para_crawl_enes</td>\n",
              "      <td>zs_opt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2681175</th>\n",
              "      <td>Q: Valid English sentence (grammatically) or n...</td>\n",
              "      <td>acceptable</td>\n",
              "      <td>Flan2021</td>\n",
              "      <td>glue/cola:2.0.0</td>\n",
              "      <td>fs_noopt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2681176</th>\n",
              "      <td>Do the following sentences say the same thing?...</td>\n",
              "      <td>5</td>\n",
              "      <td>Flan2021</td>\n",
              "      <td>glue/stsb:2.0.0</td>\n",
              "      <td>fs_noopt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2681177</th>\n",
              "      <td>Translate to Finnish:\\n\\n   The next item is t...</td>\n",
              "      <td>Esityslistalla on seuraavana yhteiskeskustelu</td>\n",
              "      <td>Flan2021</td>\n",
              "      <td>wmt16_translate/fi-en:1.0.0</td>\n",
              "      <td>zs_opt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2681178</th>\n",
              "      <td>Premise: Survival here is a creative art; it i...</td>\n",
              "      <td>(3).</td>\n",
              "      <td>Flan2021</td>\n",
              "      <td>glue/mnli:2.0.0</td>\n",
              "      <td>zs_opt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2681179</th>\n",
              "      <td>I believe that Albanian people have a democrat...</td>\n",
              "      <td>Bence Arnavut halkı, tanınması ve desteklenmes...</td>\n",
              "      <td>Flan2021</td>\n",
              "      <td>wmt16_translate/tr-en:1.0.0</td>\n",
              "      <td>zs_opt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5362361 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    inputs  \\\n",
              "0        Aleksandr Chumakov, club, FC Torpedo Moscow; F...   \n",
              "1        I kill Kurtz, they kill me, the brass running ...   \n",
              "2        i'm 10x cooler than all of you! \\nWhat is the ...   \n",
              "3        test: Tämä tarkoittaa, että avustuksia on jaet...   \n",
              "4        How do you say \"In this regard, we would like ...   \n",
              "...                                                    ...   \n",
              "2681175  Q: Valid English sentence (grammatically) or n...   \n",
              "2681176  Do the following sentences say the same thing?...   \n",
              "2681177  Translate to Finnish:\\n\\n   The next item is t...   \n",
              "2681178  Premise: Survival here is a creative art; it i...   \n",
              "2681179  I believe that Albanian people have a democrat...   \n",
              "\n",
              "                                                   targets task_source  \\\n",
              "0        Aleksandr Chumakov has played for FC Torpedo M...    Flan2021   \n",
              "1        Já zabiju Kurtze, oni zabijou mě, hlavouni, kt...    Flan2021   \n",
              "2                                                 positive    Flan2021   \n",
              "3        Returning to the Palestinian elections, I do n...    Flan2021   \n",
              "4        En este sentido, quisiéramos brindar un agrade...    Flan2021   \n",
              "...                                                    ...         ...   \n",
              "2681175                                         acceptable    Flan2021   \n",
              "2681176                                                  5    Flan2021   \n",
              "2681177      Esityslistalla on seuraavana yhteiskeskustelu    Flan2021   \n",
              "2681178                                               (3).    Flan2021   \n",
              "2681179  Bence Arnavut halkı, tanınması ve desteklenmes...    Flan2021   \n",
              "\n",
              "                           task_name template_type  \n",
              "0               gem/web_nlg_en:1.1.0      zs_noopt  \n",
              "1        wmt16_translate/cs-en:1.0.0      zs_noopt  \n",
              "2                 sentiment140:1.0.0      zs_noopt  \n",
              "3        wmt16_translate/fi-en:1.0.0      fs_noopt  \n",
              "4                    para_crawl_enes        zs_opt  \n",
              "...                              ...           ...  \n",
              "2681175              glue/cola:2.0.0      fs_noopt  \n",
              "2681176              glue/stsb:2.0.0      fs_noopt  \n",
              "2681177  wmt16_translate/fi-en:1.0.0        zs_opt  \n",
              "2681178              glue/mnli:2.0.0        zs_opt  \n",
              "2681179  wmt16_translate/tr-en:1.0.0        zs_opt  \n",
              "\n",
              "[5362361 rows x 5 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_flan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>inputs</th>\n",
              "      <th>targets</th>\n",
              "      <th>task_source</th>\n",
              "      <th>task_name</th>\n",
              "      <th>template_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>You are given a sentence in Arabic. Your job i...</td>\n",
              "      <td>اگر به گاز دی اکسید کربن ناشی از جنگل های بارا...</td>\n",
              "      <td>NIv2</td>\n",
              "      <td>task1108_ted_translation_ar_fa</td>\n",
              "      <td>zs_opt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>You will be given a definition of a task first...</td>\n",
              "      <td>اگر به گاز دی اکسید کربن ناشی از جنگل های بارا...</td>\n",
              "      <td>NIv2</td>\n",
              "      <td>task1108_ted_translation_ar_fa</td>\n",
              "      <td>fs_opt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>You will be given a definition of a task first...</td>\n",
              "      <td>6466</td>\n",
              "      <td>NIv2</td>\n",
              "      <td>task606_sum_of_all_numbers_in_list_between_pos...</td>\n",
              "      <td>zs_opt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Given the task definition, example input &amp; out...</td>\n",
              "      <td>6466</td>\n",
              "      <td>NIv2</td>\n",
              "      <td>task606_sum_of_all_numbers_in_list_between_pos...</td>\n",
              "      <td>fs_opt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Definition: In this task, you're given a state...</td>\n",
              "      <td>3</td>\n",
              "      <td>NIv2</td>\n",
              "      <td>task201_mnli_neutral_classification</td>\n",
              "      <td>zs_opt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5033443</th>\n",
              "      <td>In this task, you're given a review from Amazo...</td>\n",
              "      <td>Output: 4\\n\\n\\n</td>\n",
              "      <td>NIv2</td>\n",
              "      <td>task1310_amazonreview_rating_classification</td>\n",
              "      <td>fs_opt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5033444</th>\n",
              "      <td>You will be given a definition of a task first...</td>\n",
              "      <td>no</td>\n",
              "      <td>NIv2</td>\n",
              "      <td>task422_persent_sentence_sentiment_verification</td>\n",
              "      <td>fs_opt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5033445</th>\n",
              "      <td>In this task, you will be given a list of inte...</td>\n",
              "      <td>[-50, -80, -8]\\n\\n</td>\n",
              "      <td>NIv2</td>\n",
              "      <td>task369_synthetic_remove_odds</td>\n",
              "      <td>fs_opt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5033446</th>\n",
              "      <td>Detailed Instructions: Given a scientific ques...</td>\n",
              "      <td>Electron affinity is a measure of the energy r...</td>\n",
              "      <td>NIv2</td>\n",
              "      <td>task593_sciq_explanation_generation</td>\n",
              "      <td>zs_opt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5033447</th>\n",
              "      <td>You're given a sentence and your task is to cl...</td>\n",
              "      <td>unacceptable\\n****\\n</td>\n",
              "      <td>NIv2</td>\n",
              "      <td>task616_cola_classification</td>\n",
              "      <td>fs_opt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10066896 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    inputs  \\\n",
              "0        You are given a sentence in Arabic. Your job i...   \n",
              "1        You will be given a definition of a task first...   \n",
              "2        You will be given a definition of a task first...   \n",
              "3        Given the task definition, example input & out...   \n",
              "4        Definition: In this task, you're given a state...   \n",
              "...                                                    ...   \n",
              "5033443  In this task, you're given a review from Amazo...   \n",
              "5033444  You will be given a definition of a task first...   \n",
              "5033445  In this task, you will be given a list of inte...   \n",
              "5033446  Detailed Instructions: Given a scientific ques...   \n",
              "5033447  You're given a sentence and your task is to cl...   \n",
              "\n",
              "                                                   targets task_source  \\\n",
              "0        اگر به گاز دی اکسید کربن ناشی از جنگل های بارا...        NIv2   \n",
              "1        اگر به گاز دی اکسید کربن ناشی از جنگل های بارا...        NIv2   \n",
              "2                                                     6466        NIv2   \n",
              "3                                                     6466        NIv2   \n",
              "4                                                        3        NIv2   \n",
              "...                                                    ...         ...   \n",
              "5033443                                    Output: 4\\n\\n\\n        NIv2   \n",
              "5033444                                                 no        NIv2   \n",
              "5033445                                 [-50, -80, -8]\\n\\n        NIv2   \n",
              "5033446  Electron affinity is a measure of the energy r...        NIv2   \n",
              "5033447                               unacceptable\\n****\\n        NIv2   \n",
              "\n",
              "                                                 task_name template_type  \n",
              "0                           task1108_ted_translation_ar_fa        zs_opt  \n",
              "1                           task1108_ted_translation_ar_fa        fs_opt  \n",
              "2        task606_sum_of_all_numbers_in_list_between_pos...        zs_opt  \n",
              "3        task606_sum_of_all_numbers_in_list_between_pos...        fs_opt  \n",
              "4                      task201_mnli_neutral_classification        zs_opt  \n",
              "...                                                    ...           ...  \n",
              "5033443        task1310_amazonreview_rating_classification        fs_opt  \n",
              "5033444    task422_persent_sentence_sentiment_verification        fs_opt  \n",
              "5033445                      task369_synthetic_remove_odds        fs_opt  \n",
              "5033446                task593_sciq_explanation_generation        zs_opt  \n",
              "5033447                        task616_cola_classification        fs_opt  \n",
              "\n",
              "[10066896 rows x 5 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_niv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>inputs</th>\n",
              "      <th>targets</th>\n",
              "      <th>task_source</th>\n",
              "      <th>task_name</th>\n",
              "      <th>template_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Q: What type of molecules sit within a membran...</td>\n",
              "      <td>the abdomen\\n--</td>\n",
              "      <td>P3</td>\n",
              "      <td>sciq_Direct_Question_Closed_Book_</td>\n",
              "      <td>fs_noopt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>- headercolor is lightsteelblue    - birth dat...</td>\n",
              "      <td>Ans: wandee kameaim</td>\n",
              "      <td>P3</td>\n",
              "      <td>wiki_bio_guess_person</td>\n",
              "      <td>fs_noopt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Read the following article and select the best...</td>\n",
              "      <td>Thomas Jefferson</td>\n",
              "      <td>P3</td>\n",
              "      <td>race_high_Select_the_best_answer_generate_span_</td>\n",
              "      <td>fs_noopt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Information:  - Chand Bardai (  , September 30...</td>\n",
              "      <td>rajasthan</td>\n",
              "      <td>P3</td>\n",
              "      <td>wiki_hop_original_choose_best_object_affirmati...</td>\n",
              "      <td>zs_opt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>When Patch finally found his way out of the se...</td>\n",
              "      <td>D</td>\n",
              "      <td>P3</td>\n",
              "      <td>quail_no_prompt_id</td>\n",
              "      <td>zs_noopt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1650303</th>\n",
              "      <td>Please answer the following question: John was...</td>\n",
              "      <td>era A</td>\n",
              "      <td>P3</td>\n",
              "      <td>ropes_plain_bottom_hint</td>\n",
              "      <td>zs_noopt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1650304</th>\n",
              "      <td>Robin gained a lot of muscle so that she would...</td>\n",
              "      <td>go to the gym to workout</td>\n",
              "      <td>P3</td>\n",
              "      <td>social_i_qa_Show_choices_and_generate_answer</td>\n",
              "      <td>zs_opt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1650305</th>\n",
              "      <td>input question: Question: The drawing room was...</td>\n",
              "      <td>rug dog is get completely dirty</td>\n",
              "      <td>P3</td>\n",
              "      <td>cos_e_v1.11_explain_why_human</td>\n",
              "      <td>fs_opt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1650306</th>\n",
              "      <td>Q:Skylar heard a voice in her head saying her ...</td>\n",
              "      <td>save her husband from injury</td>\n",
              "      <td>P3</td>\n",
              "      <td>social_i_qa_Show_choices_and_generate_answer</td>\n",
              "      <td>zs_opt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1650307</th>\n",
              "      <td>Information:  - North Dakota (locally ) is the...</td>\n",
              "      <td>list of cities in south dakota , city</td>\n",
              "      <td>P3</td>\n",
              "      <td>wiki_hop_original_generate_subject_and_object</td>\n",
              "      <td>zs_opt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1650308 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    inputs  \\\n",
              "0        Q: What type of molecules sit within a membran...   \n",
              "1        - headercolor is lightsteelblue    - birth dat...   \n",
              "2        Read the following article and select the best...   \n",
              "3        Information:  - Chand Bardai (  , September 30...   \n",
              "4        When Patch finally found his way out of the se...   \n",
              "...                                                    ...   \n",
              "1650303  Please answer the following question: John was...   \n",
              "1650304  Robin gained a lot of muscle so that she would...   \n",
              "1650305  input question: Question: The drawing room was...   \n",
              "1650306  Q:Skylar heard a voice in her head saying her ...   \n",
              "1650307  Information:  - North Dakota (locally ) is the...   \n",
              "\n",
              "                                       targets task_source  \\\n",
              "0                              the abdomen\\n--          P3   \n",
              "1                          Ans: wandee kameaim          P3   \n",
              "2                             Thomas Jefferson          P3   \n",
              "3                                    rajasthan          P3   \n",
              "4                                            D          P3   \n",
              "...                                        ...         ...   \n",
              "1650303                                  era A          P3   \n",
              "1650304               go to the gym to workout          P3   \n",
              "1650305        rug dog is get completely dirty          P3   \n",
              "1650306           save her husband from injury          P3   \n",
              "1650307  list of cities in south dakota , city          P3   \n",
              "\n",
              "                                                 task_name template_type  \n",
              "0                        sciq_Direct_Question_Closed_Book_      fs_noopt  \n",
              "1                                    wiki_bio_guess_person      fs_noopt  \n",
              "2          race_high_Select_the_best_answer_generate_span_      fs_noopt  \n",
              "3        wiki_hop_original_choose_best_object_affirmati...        zs_opt  \n",
              "4                                       quail_no_prompt_id      zs_noopt  \n",
              "...                                                    ...           ...  \n",
              "1650303                            ropes_plain_bottom_hint      zs_noopt  \n",
              "1650304       social_i_qa_Show_choices_and_generate_answer        zs_opt  \n",
              "1650305                      cos_e_v1.11_explain_why_human        fs_opt  \n",
              "1650306       social_i_qa_Show_choices_and_generate_answer        zs_opt  \n",
              "1650307      wiki_hop_original_generate_subject_and_object        zs_opt  \n",
              "\n",
              "[1650308 rows x 5 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_t0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since The Combined Dataset of `FLAN-V2` is very huge and the kernel dies in case of less computational resources. To avoid that we will only take proportions of that Datasets, combine and then preprocess."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove instructions with less than 100 tokens in response.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "SlAnyZBHZ9Kd"
      ],
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
